{"version":3,"sources":["src/firestore/local/local_store.ts","firestore/local/local_store.js"],"names":["log","objUtils","LOG_TAG","LocalStore","persistence","initialUser","garbageCollector","localViewReferences","targetIds","targetIdGenerator","forLocalStore","heldBatchResults","mutationQueue","getMutationQueue","remoteDocuments","getRemoteDocumentCache","queryCache","getQueryCache","localDocuments","addGarbageSource","prototype","start","_this","runTransaction","txn","startMutationQueue","next","startQueryCache","handleUserChange","user","oldBatches","getAllMutationBatches","promisedOldBatches","removeGarbageSource","newBatches","changedKeys","_i","_a","length","batches","_b","batches_1","batch","_c","_d","mutations","mutation","add","key","getDocuments","targetId","getHighestTargetId","getHighestAcknowledgedBatchId","highestAck","getAllMutationBatchesThroughBatchId","resolve","ackedBatches","removeMutationBatches","localWrite","localWriteTime","now","addMutationBatch","promisedBatch","keys","changedDocuments","batchId","changes","acknowledgeBatch","batchResult","affected","streamToken","shouldHoldBatchResult","commitVersion","push","documentBuffer_1","releaseBatchResults","promisedAffectedKeys","apply","performConsistencyCheck","rejectBatch","toReject","affectedKeys","lookupMutationBatch","promisedToReject","lastAcked","removeMutationBatch","getLastStreamToken","setLastStreamToken","getLastRemoteSnapshotVersion","applyRemoteEvent","remoteEvent","documentBuffer","promises","forEachNumber","targetChanges","change","queryData","mapping","removeMatchingKeysForTargetId","addMatchingKeys","documents","removeMatchingKeys","removedDocuments","addedDocuments","JSON","stringify","resumeToken","update","snapshotVersion","addQueryData","changedDocKeys","documentUpdates","forEach","doc","getEntry","existingDoc","version","equals","MIN","compareTo","addEntry","debug","addPotentialGarbageKey","lastRemoteVersion","remoteVersion","setLastRemoteSnapshotVersion","releasedWriteKeys","waitFor","releaseHeldBatchResults","promisedReleasedWriteKeys","unionWith","notifyLocalViewChanges","viewChanges","_loop_1","view","getQueryData","query","addReferences","addedKeys","removeReferences","removedKeys","viewChanges_1","nextMutationBatch","afterBatchId","undefined","getNextMutationBatchAfterBatchId","readDocument","getDocument","allocateQuery","cached","Listen","releaseQuery","removeReferencesForId","isEager","removeQueryData","isEmpty","documentBuffer_2","executeQuery","getDocumentsMatchingQuery","remoteDocumentKeys","getMatchingKeysForTargetId","collectGarbage","garbage","removeEntry","toRelease","isRemoteUpToVersion","splice","batchResults","promiseChain","_loop_2","applyWriteToRemoteDocuments","batchResults_1","map","result","affectedDocs","batches_2","docKeys","docKey","remoteDoc","ackVersion","docVersions","get","applyToRemoteDocument"],"mappings":";;;;;;;AAkBA;;AACA;;AACA;;AAEA;;AASA;;AAKA;;AAMA;;AACA;;IAAYA,G;;AACZ;;IAAYC,Q;;AAIZ;;AAIA;;AAEA;;AACA;;AAEA;;;;AAzDA;;;;;;;;;;;;;;;AA2DA,IAAMC,UAAU,YAAhB;AAQA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmDA,IAAAC,aAAA,aAAA,YAAA;AA0CE,aAAAA,UAAA;AACE;AACQC,eAFV,EAGEC,WAHF;AAIE;;;;;AAKQC,oBATV,EAS4C;AAPlC,aAAAF,WAAA,GAAAA,WAAA;AAOA,aAAAE,gBAAA,GAAAA,gBAAA;AAnCV;;;AAGQ,aAAAC,mBAAA,GAAsB,iCAAtB;AAKR;AACQ,aAAAC,SAAA,GAAY,EAAZ;AAER;AACQ,aAAAC,iBAAA,GAAoB,uCAAkBC,aAAlB,EAApB;AAER;;;;;;;;;;AAUQ,aAAAC,gBAAA,GAA0C,EAA1C;AAaN,aAAKC,aAAL,GAAqBR,YAAYS,gBAAZ,CAA6BR,WAA7B,CAArB;AACA,aAAKS,eAAL,GAAuBV,YAAYW,sBAAZ,EAAvB;AACA,aAAKC,UAAL,GAAkBZ,YAAYa,aAAZ,EAAlB;AACA,aAAKC,cAAL,GAAsB,6CACpB,KAAKJ,eADe,EAEpB,KAAKF,aAFe,CAAtB;AAIA,aAAKN,gBAAL,CAAsBa,gBAAtB,CAAuC,KAAKZ,mBAA5C;AACA,aAAKD,gBAAL,CAAsBa,gBAAtB,CAAuC,KAAKH,UAA5C;AACA,aAAKV,gBAAL,CAAsBa,gBAAtB,CAAuC,KAAKP,aAA5C;AACD;AAED;AACAT,eAAAiB,SAAA,CAAAC,KAAA,GAAA,YAAA;AAAA,YAAAC,QAAA,IAAA;AACE,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,kBAAhC,EAAoD,UAAAC,GAAA,EAAG;AAC5D,mBAAOF,MAAKG,kBAAL,CAAwBD,GAAxB,EAA6BE,IAA7B,CAAkC,YAAA;AAAM,uBAAAJ,MAAKK,eAAL,CAAqBH,GAArB,CAAA;AAAyB,aAAjE,CAAP;AACD,SAFM,CAAP;AAGD,KAJD;AAMA;;;;;;AAMArB,eAAAiB,SAAA,CAAAQ,gBAAA,GAAA,UAAiBC,IAAjB,EAA2B;AAA3B,YAAAP,QAAA,IAAA;AACE,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,oBAAhC,EAAsD,UAAAC,GAAA,EAAG;AAC9D;AACA;AACA,gBAAIM,UAAJ;AACA,mBAAOR,MAAKV,aAAL,CACJmB,qBADI,CACkBP,GADlB,EAEJE,IAFI,CAEC,UAAAM,kBAAA,EAAkB;AACtBF,6BAAaE,kBAAb;AAEAV,sBAAKhB,gBAAL,CAAsB2B,mBAAtB,CAA0CX,MAAKV,aAA/C;AACAU,sBAAKV,aAAL,GAAqBU,MAAKlB,WAAL,CAAiBS,gBAAjB,CAAkCgB,IAAlC,CAArB;AACAP,sBAAKhB,gBAAL,CAAsBa,gBAAtB,CAAuCG,MAAKV,aAA5C;AACA,uBAAOU,MAAKG,kBAAL,CAAwBD,GAAxB,CAAP;AACD,aATI,EAUJE,IAVI,CAUC,YAAA;AACJ;AACA;AACAJ,sBAAKJ,cAAL,GAAsB,6CACpBI,MAAKR,eADe,EAEpBQ,MAAKV,aAFe,CAAtB;AAIA,uBAAOU,MAAKV,aAAL,CAAmBmB,qBAAnB,CAAyCP,GAAzC,CAAP;AACD,aAlBI,EAmBJE,IAnBI,CAmBC,UAAAQ,UAAA,EAAU;AACd;AACA,oBAAIC,cAAc,kCAAlB;AACA,qBAAsB,IAAAC,KAAA,CAAA,EAAAC,KAAA,CAACP,UAAD,EAAaI,UAAb,CAAtB,EAAsBE,KAAAC,GAAAC,MAAtB,EAAsBF,IAAtB,EAA8C;AAAzC,wBAAMG,UAAOF,GAAAD,EAAA,CAAb;AACH,yBAAoB,IAAAI,KAAA,CAAA,EAAAC,YAAAF,OAApB,EAAoBC,KAAAC,UAAAH,MAApB,EAAoBE,IAApB,EAA2B;AAAtB,4BAAME,QAAKD,UAAAD,EAAA,CAAX;AACH,6BAAuB,IAAAG,KAAA,CAAA,EAAAC,KAAAF,MAAMG,SAA7B,EAAuBF,KAAAC,GAAAN,MAAvB,EAAuBK,IAAvB,EAAsC;AAAjC,gCAAMG,WAAQF,GAAAD,EAAA,CAAd;AACHR,0CAAcA,YAAYY,GAAZ,CAAgBD,SAASE,GAAzB,CAAd;AACD;AACF;AACF;AAED;AACA;AACA,uBAAO1B,MAAKJ,cAAL,CAAoB+B,YAApB,CAAiCzB,GAAjC,EAAsCW,WAAtC,CAAP;AACD,aAjCI,CAAP;AAkCD,SAtCM,CAAP;AAuCD,KAxCD;AA0CQhC,eAAAiB,SAAA,CAAAO,eAAA,GAAR,UACEH,GADF,EAC6B;AAD7B,YAAAF,QAAA,IAAA;AAGE,eAAO,KAAKN,UAAL,CAAgBK,KAAhB,CAAsBG,GAAtB,EAA2BE,IAA3B,CAAgC,YAAA;AACrC,gBAAMwB,WAAW5B,MAAKN,UAAL,CAAgBmC,kBAAhB,EAAjB;AACA7B,kBAAKb,iBAAL,GAAyB,uCAAkBC,aAAlB,CAAgCwC,QAAhC,CAAzB;AACD,SAHM,CAAP;AAID,KAPO;AASA/C,eAAAiB,SAAA,CAAAK,kBAAA,GAAR,UACED,GADF,EAC6B;AAD7B,YAAAF,QAAA,IAAA;AAGE,eAAO,KAAKV,aAAL,CACJS,KADI,CACEG,GADF,EAEJE,IAFI,CAEC,YAAA;AACJ;AACA;AACA;AACA;AACA;AACAJ,kBAAKX,gBAAL,GAAwB,EAAxB;AACA,mBAAOW,MAAKV,aAAL,CAAmBwC,6BAAnB,CAAiD5B,GAAjD,CAAP;AACD,SAVI,EAWJE,IAXI,CAWC,UAAA2B,UAAA,EAAU;AACd;AACA;AACA;AACA,gBAAIA,8CAAJ,EAAoC;AAClC,uBAAO/B,MAAKV,aAAL,CAAmB0C,mCAAnB,CACL9B,GADK,EAEL6B,UAFK,CAAP;AAID,aALD,MAKO;AACL,uBAAO,wCAAmBE,OAAnB,CAA2B,EAA3B,CAAP;AACD;AACF,SAvBI,EAwBJ7B,IAxBI,CAwBC,UAAA8B,YAAA,EAAY;AAChB,gBAAIA,aAAalB,MAAb,GAAsB,CAA1B,EAA6B;AAC3B,uBAAOhB,MAAKV,aAAL,CAAmB6C,qBAAnB,CAAyCjC,GAAzC,EAA8CgC,YAA9C,CAAP;AACD,aAFD,MAEO;AACL,uBAAO,wCAAmBD,OAAnB,EAAP;AACD;AACF,SA9BI,CAAP;AA+BD,KAlCO;AAoCR;AACApD,eAAAiB,SAAA,CAAAsC,UAAA,GAAA,UAAWb,SAAX,EAAgC;AAAhC,YAAAvB,QAAA,IAAA;AACE,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,yBAAhC,EAA2D,UAAAC,GAAA,EAAG;AACnE,gBAAIkB,KAAJ;AACA,gBAAMiB,iBAAiB,qBAAUC,GAAV,EAAvB;AACA,mBAAOtC,MAAKV,aAAL,CACJiD,gBADI,CACarC,GADb,EACkBmC,cADlB,EACkCd,SADlC,EAEJnB,IAFI,CAEC,UAAAoC,aAAA,EAAa;AACjBpB,wBAAQoB,aAAR;AACA;AACA;AACA;AACA,oBAAMC,OAAOrB,MAAMqB,IAAN,EAAb;AACA,uBAAOzC,MAAKJ,cAAL,CAAoB+B,YAApB,CAAiCzB,GAAjC,EAAsCuC,IAAtC,CAAP;AACD,aATI,EAUJrC,IAVI,CAUC,UAACsC,gBAAD,EAAmC;AACvC,uBAAO,EAAEC,SAASvB,MAAMuB,OAAjB,EAA0BC,SAASF,gBAAnC,EAAP;AACD,aAZI,CAAP;AAaD,SAhBM,CAAP;AAiBD,KAlBD;AAoBA;;;;;;;;;;;;;;AAcA7D,eAAAiB,SAAA,CAAA+C,gBAAA,GAAA,UACEC,WADF,EACkC;AADlC,YAAA9C,QAAA,IAAA;AAGE,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,mBAAhC,EAAqD,UAAAC,GAAA,EAAG;AAC7D,gBAAI6C,QAAJ;AACA,mBAAO/C,MAAKV,aAAL,CACJuD,gBADI,CACa3C,GADb,EACkB4C,YAAY1B,KAD9B,EACqC0B,YAAYE,WADjD,EAEJ5C,IAFI,CAEC,YAAA;AACJ,oBAAIJ,MAAKiD,qBAAL,CAA2BH,YAAYI,aAAvC,CAAJ,EAA2D;AACzDlD,0BAAKX,gBAAL,CAAsB8D,IAAtB,CAA2BL,WAA3B;AACAC,+BAAW,kCAAX;AACA,2BAAO,wCAAmBd,OAAnB,EAAP;AACD,iBAJD,MAIO;AACL,wBAAMmB,mBAAiB,8DACrBpD,MAAKR,eADgB,CAAvB;AAGA,2BAAOQ,MAAKqD,mBAAL,CACLnD,GADK,EAEL,CAAC4C,WAAD,CAFK,EAGLM,gBAHK,EAILhD,IAJK,CAIA,UAAAkD,oBAAA,EAAoB;AACzBP,mCAAWO,oBAAX;AACA,+BAAOF,iBAAeG,KAAf,CAAqBrD,GAArB,CAAP;AACD,qBAPM,CAAP;AAQD;AACF,aApBI,EAqBJE,IArBI,CAqBC,YAAA;AACJ,uBAAOJ,MAAKV,aAAL,CAAmBkE,uBAAnB,CAA2CtD,GAA3C,CAAP;AACD,aAvBI,EAwBJE,IAxBI,CAwBC,YAAA;AACJ,uBAAOJ,MAAKJ,cAAL,CAAoB+B,YAApB,CAAiCzB,GAAjC,EAAsC6C,QAAtC,CAAP;AACD,aA1BI,CAAP;AA2BD,SA7BM,CAAP;AA8BD,KAjCD;AAmCA;;;;;;AAMAlE,eAAAiB,SAAA,CAAA2D,WAAA,GAAA,UAAYd,OAAZ,EAA4B;AAA5B,YAAA3C,QAAA,IAAA;AACE,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,cAAhC,EAAgD,UAAAC,GAAA,EAAG;AACxD,gBAAIwD,QAAJ;AACA,gBAAIC,YAAJ;AACA,mBAAO3D,MAAKV,aAAL,CACJsE,mBADI,CACgB1D,GADhB,EACqByC,OADrB,EAEJvC,IAFI,CAEC,UAACyD,gBAAD,EAAuC;AAC3C,oCACEA,oBAAoB,IADtB,EAEE,sCAFF;AAIAH,2BAAWG,gBAAX;AAEA,uBAAO7D,MAAKV,aAAL,CACJwC,6BADI,CAC0B5B,GAD1B,EAEJE,IAFI,CAEC,UAAA0D,SAAA,EAAS;AACb,wCACEnB,UAAUmB,SADZ,EAEE,yCAFF;AAIA,2BAAOJ,QAAP;AACD,iBARI,CAAP;AASD,aAlBI,EAmBJtD,IAnBI,CAmBC,YAAA;AACJ,uBAAOJ,MAAK+D,mBAAL,CAAyB7D,GAAzB,EAA8BwD,QAA9B,CAAP;AACD,aArBI,EAsBJtD,IAtBI,CAsBC,UAAAkD,oBAAA,EAAoB;AACxBK,+BAAeL,oBAAf;AACA,uBAAOtD,MAAKV,aAAL,CAAmBkE,uBAAnB,CAA2CtD,GAA3C,CAAP;AACD,aAzBI,EA0BJE,IA1BI,CA0BC,YAAA;AACJ,uBAAOJ,MAAKJ,cAAL,CAAoB+B,YAApB,CAAiCzB,GAAjC,EAAsCyD,YAAtC,CAAP;AACD,aA5BI,CAAP;AA6BD,SAhCM,CAAP;AAiCD,KAlCD;AAoCA;AACA9E,eAAAiB,SAAA,CAAAkE,kBAAA,GAAA,YAAA;AAAA,YAAAhE,QAAA,IAAA;AACE,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,uBAAhC,EAAyD,UAAAC,GAAA,EAAG;AACjE,mBAAOF,MAAKV,aAAL,CAAmB0E,kBAAnB,CAAsC9D,GAAtC,CAAP;AACD,SAFM,CAAP;AAGD,KAJD;AAMA;;;;;AAKArB,eAAAiB,SAAA,CAAAmE,kBAAA,GAAA,UAAmBjB,WAAnB,EAA+C;AAA/C,YAAAhD,QAAA,IAAA;AACE,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,uBAAhC,EAAyD,UAAAC,GAAA,EAAG;AACjE,mBAAOF,MAAKV,aAAL,CAAmB2E,kBAAnB,CAAsC/D,GAAtC,EAA2C8C,WAA3C,CAAP;AACD,SAFM,CAAP;AAGD,KAJD;AAMA;;;;AAIAnE,eAAAiB,SAAA,CAAAoE,4BAAA,GAAA,YAAA;AACE,eAAO,KAAKxE,UAAL,CAAgBwE,4BAAhB,EAAP;AACD,KAFD;AAIA;;;;;;;;AAQArF,eAAAiB,SAAA,CAAAqE,gBAAA,GAAA,UAAiBC,WAAjB,EAAyC;AAAzC,YAAApE,QAAA,IAAA;AACE,YAAMqE,iBAAiB,8DAA+B,KAAK7E,eAApC,CAAvB;AACA,eAAO,KAAKV,WAAL,CAAiBmB,cAAjB,CAAgC,oBAAhC,EAAsD,UAAAC,GAAA,EAAG;AAC9D,gBAAMoE,WAAW,EAAjB;AACA3F,qBAAS4F,aAAT,CACEH,YAAYI,aADd,EAEE,UAAC5C,QAAD,EAAqB6C,MAArB,EAAyC;AACvC;AACA,oBAAIC,YAAY1E,MAAKd,SAAL,CAAe0C,QAAf,CAAhB;AACA,oBAAI,CAAC8C,SAAL,EAAgB;AAEhB,oBAAMC,UAAwCF,OAAOE,OAArD;AACA,oBAAIA,OAAJ,EAAa;AACX;AACA,wBAAIA,6CAAJ,EAAqC;AACnCL,iCAASnB,IAAT,CACEnD,MAAKN,UAAL,CACGkF,6BADH,CACiC1E,GADjC,EACsC0B,QADtC,EAEGxB,IAFH,CAEQ,YAAA;AACJ,mCAAOJ,MAAKN,UAAL,CAAgBmF,eAAhB,CACL3E,GADK,EAELyE,QAAQG,SAFH,EAGLlD,QAHK,CAAP;AAKD,yBARH,CADF;AAWD,qBAZD,MAYO,IAAI+C,8CAAJ,EAAsC;AAC3CL,iCAASnB,IAAT,CACEnD,MAAKN,UAAL,CACGqF,kBADH,CACsB7E,GADtB,EAC2ByE,QAAQK,gBADnC,EACqDpD,QADrD,EAEGxB,IAFH,CAEQ,YAAA;AACJ,mCAAOJ,MAAKN,UAAL,CAAgBmF,eAAhB,CACL3E,GADK,EAELyE,QAAQM,cAFH,EAGLrD,QAHK,CAAP;AAKD,yBARH,CADF;AAWD,qBAZM,MAYA;AACL,+BAAO,kBAAK,2BAA2BsD,KAAKC,SAAL,CAAeR,OAAf,CAAhC,CAAP;AACD;AACF;AAED;AACA;AACA,oBAAMS,cAAcX,OAAOW,WAA3B;AACA,oBAAIA,YAAYpE,MAAZ,GAAqB,CAAzB,EAA4B;AAC1B0D,gCAAYA,UAAUW,MAAV,CAAiB;AAC3BD,qCAAWA,WADgB;AAE3BE,yCAAiBb,OAAOa;AAFG,qBAAjB,CAAZ;AAIAtF,0BAAKd,SAAL,CAAe0C,QAAf,IAA2B8C,SAA3B;AACAJ,6BAASnB,IAAT,CAAcnD,MAAKN,UAAL,CAAgB6F,YAAhB,CAA6BrF,GAA7B,EAAkCwE,SAAlC,CAAd;AACD;AACF,aAlDH;AAqDA,gBAAIc,iBAAiB,kCAArB;AACApB,wBAAYqB,eAAZ,CAA4BC,OAA5B,CAAoC,UAAChE,GAAD,EAAMiE,GAAN,EAAS;AAC3CH,iCAAiBA,eAAe/D,GAAf,CAAmBC,GAAnB,CAAjB;AACA4C,yBAASnB,IAAT,CACEkB,eAAeuB,QAAf,CAAwB1F,GAAxB,EAA6BwB,GAA7B,EAAkCtB,IAAlC,CAAuC,UAAAyF,WAAA,EAAW;AAChD;AACA;AACA;AACA;AACA,wBACEA,eAAe,IAAf,IACAF,IAAIG,OAAJ,CAAYC,MAAZ,CAAmB,kCAAgBC,GAAnC,CADA,IAEAL,IAAIG,OAAJ,CAAYG,SAAZ,CAAsBJ,YAAYC,OAAlC,KAA8C,CAHhD,EAIE;AACAzB,uCAAe6B,QAAf,CAAwBP,GAAxB;AACD,qBAND,MAMO;AACLjH,4BAAIyH,KAAJ,CACEvH,OADF,EAEE,qCAFF,EAGE8C,GAHF,EAIE,oBAJF,EAKEmE,YAAYC,OALd,EAME,iBANF,EAOEH,IAAIG,OAPN;AASD;AAED;AACA;AACA9F,0BAAKhB,gBAAL,CAAsBoH,sBAAtB,CAA6C1E,GAA7C;AACD,iBA1BD,CADF;AA6BD,aA/BD;AAiCA;AACA;AACA;AACA;AACA,gBAAM2E,oBAAoBrG,MAAKN,UAAL,CAAgBwE,4BAAhB,EAA1B;AACA,gBAAMoC,gBAAgBlC,YAAYkB,eAAlC;AACA,gBAAI,CAACgB,cAAcP,MAAd,CAAqB,kCAAgBC,GAArC,CAAL,EAAgD;AAC9C,oCACEM,cAAcL,SAAd,CAAwBI,iBAAxB,KAA8C,CADhD,EAEE,kDACEC,aADF,GAEE,KAFF,GAGED,iBALJ;AAOA/B,yBAASnB,IAAT,CACEnD,MAAKN,UAAL,CAAgB6G,4BAAhB,CAA6CrG,GAA7C,EAAkDoG,aAAlD,CADF;AAGD;AAED,gBAAIE,iBAAJ;AACA,mBAAO,wCAAmBC,OAAnB,CAA2BnC,QAA3B,EACJlE,IADI,CACC,YAAA;AAAM,uBAAAJ,MAAK0G,uBAAL,CAA6BxG,GAA7B,EAAkCmE,cAAlC,CAAA;AAAiD,aADxD,EAEJjE,IAFI,CAEC,UAAAuG,yBAAA,EAAyB;AAC7BH,oCAAoBG,yBAApB;AACA,uBAAOtC,eAAed,KAAf,CAAqBrD,GAArB,CAAP;AACD,aALI,EAMJE,IANI,CAMC,YAAA;AACJ,uBAAOJ,MAAKJ,cAAL,CAAoB+B,YAApB,CACLzB,GADK,EAELsF,eAAeoB,SAAf,CAAyBJ,iBAAzB,CAFK,CAAP;AAID,aAXI,CAAP;AAYD,SAzHM,CAAP;AA0HD,KA5HD;AA8HA;;;AAGA3H,eAAAiB,SAAA,CAAA+G,sBAAA,GAAA,UAAuBC,WAAvB,EAAsD;AAAtD,YAAA9G,QAAA,IAAA;AACE,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,2BAAhC,EAA6D,UAAAC,GAAA,EAAG;AACrE,gBAAMoE,WAAW,EAAjB;ACxHM,gBAAIyC,UAAU,SAAVA,OAAU,CDyHTC,ICzHS,EDyHL;AACb1C,yBAASnB,IAAT,CACEnD,MAAKN,UAAL,CACGuH,YADH,CACgB/G,GADhB,EACqB8G,KAAKE,KAD1B,EAEG9G,IAFH,CAEQ,UAACsE,SAAD,EAA4B;AAChC,wCACEA,cAAc,IADhB,EAEE,+CAFF;AAIA,wBAAM9C,WAAW8C,UAAW9C,QAA5B;AACA5B,0BAAKf,mBAAL,CAAyBkI,aAAzB,CAAuCH,KAAKI,SAA5C,EAAuDxF,QAAvD;AACA5B,0BAAKf,mBAAL,CAAyBoI,gBAAzB,CACEL,KAAKM,WADP,EAEE1F,QAFF;AAID,iBAbH,CADF;AAgBD,aC1IK;ADyHN,iBAAmB,IAAAd,KAAA,CAAA,EAAAyG,gBAAAT,WAAnB,EAAmBhG,KAAAyG,cAAAvG,MAAnB,EAAmBF,IAAnB,EAA8B;AAAzB,oBAAMkG,OAAIO,cAAAzG,EAAA,CAAV;AC7GKiG,wBD6GCC,IC7GD;AD8HT;AACD,mBAAO,wCAAmBP,OAAnB,CAA2BnC,QAA3B,CAAP;AACD,SArBM,CAAP;AAsBD,KAvBD;AAyBA;;;;;;AAMAzF,eAAAiB,SAAA,CAAA0H,iBAAA,GAAA,UAAkBC,YAAlB,EAAwC;AAAxC,YAAAzH,QAAA,IAAA;AACE,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,yBAAhC,EAA2D,UAAAC,GAAA,EAAG;AACnE,gBAAIuH,iBAAiBC,SAArB,EAAgC;AAC9BD;AACD;AACD,mBAAOzH,MAAKV,aAAL,CAAmBqI,gCAAnB,CACLzH,GADK,EAELuH,YAFK,CAAP;AAID,SARM,CAAP;AASD,KAVD;AAYA;;;;AAIA5I,eAAAiB,SAAA,CAAA8H,YAAA,GAAA,UAAalG,GAAb,EAA6B;AAA7B,YAAA1B,QAAA,IAAA;AACE,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,eAAhC,EAAiD,UAAAC,GAAA,EAAG;AACzD,mBAAOF,MAAKJ,cAAL,CAAoBiI,WAApB,CAAgC3H,GAAhC,EAAqCwB,GAArC,CAAP;AACD,SAFM,CAAP;AAGD,KAJD;AAMA;;;;;AAKA7C,eAAAiB,SAAA,CAAAgI,aAAA,GAAA,UAAcZ,KAAd,EAA0B;AAA1B,YAAAlH,QAAA,IAAA;AACE,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,gBAAhC,EAAkD,UAAAC,GAAA,EAAG;AAC1D,gBAAIwE,SAAJ;AACA,mBAAO1E,MAAKN,UAAL,CACJuH,YADI,CACS/G,GADT,EACcgH,KADd,EAEJ9G,IAFI,CAEC,UAAC2H,MAAD,EAAyB;AAC7B,oBAAIA,MAAJ,EAAY;AACV;AACA;AACA;AACArD,gCAAYqD,MAAZ;AACA,2BAAO,wCAAmB9F,OAAnB,EAAP;AACD,iBAND,MAMO;AACL,wBAAML,WAAW5B,MAAKb,iBAAL,CAAuBiB,IAAvB,EAAjB;AACAsE,gCAAY,0BAAcwC,KAAd,EAAqBtF,QAArB,EAA+B,yBAAaoG,MAA5C,CAAZ;AACA,2BAAOhI,MAAKN,UAAL,CAAgB6F,YAAhB,CAA6BrF,GAA7B,EAAkCwE,SAAlC,CAAP;AACD;AACF,aAdI,EAeJtE,IAfI,CAeC,YAAA;AACJ,oCACE,CAACJ,MAAKd,SAAL,CAAewF,UAAU9C,QAAzB,CADH,EAEE,mDAAmDsF,KAFrD;AAIAlH,sBAAKd,SAAL,CAAewF,UAAU9C,QAAzB,IAAqC8C,SAArC;AACA,uBAAOA,SAAP;AACD,aAtBI,CAAP;AAuBD,SAzBM,CAAP;AA0BD,KA3BD;AA6BA;AACA7F,eAAAiB,SAAA,CAAAmI,YAAA,GAAA,UAAaf,KAAb,EAAyB;AAAzB,YAAAlH,QAAA,IAAA;AACE,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,eAAhC,EAAiD,UAAAC,GAAA,EAAG;AACzD,mBAAOF,MAAKN,UAAL,CACJuH,YADI,CACS/G,GADT,EACcgH,KADd,EAEJ9G,IAFI,CAEC,UAACsE,SAAD,EAA4B;AAChC,oCACEA,aAAa,IADf,EAEE,yCAAyCwC,KAF3C;AAIAlH,sBAAKf,mBAAL,CAAyBiJ,qBAAzB,CAA+CxD,UAAW9C,QAA1D;AACA,uBAAO5B,MAAKd,SAAL,CAAewF,UAAW9C,QAA1B,CAAP;AACA,oBAAI5B,MAAKhB,gBAAL,CAAsBmJ,OAA1B,EAAmC;AACjC,2BAAOnI,MAAKN,UAAL,CAAgB0I,eAAhB,CAAgClI,GAAhC,EAAqCwE,SAArC,CAAP;AACD,iBAFD,MAEO;AACL,2BAAO,wCAAmBzC,OAAnB,EAAP;AACD;AACF,aAdI,EAeJ7B,IAfI,CAeC,YAAA;AACJ;AACA;AACA,oBAAIzB,SAAS0J,OAAT,CAAiBrI,MAAKd,SAAtB,CAAJ,EAAsC;AACpC,wBAAMoJ,mBAAiB,8DACrBtI,MAAKR,eADgB,CAAvB;AAGA,2BAAOQ,MAAK0G,uBAAL,CACLxG,GADK,EAELoI,gBAFK,EAGLlI,IAHK,CAGA,YAAA;AACLkI,yCAAe/E,KAAf,CAAqBrD,GAArB;AACD,qBALM,CAAP;AAMD,iBAVD,MAUO;AACL,2BAAO,wCAAmB+B,OAAnB,EAAP;AACD;AACF,aA/BI,CAAP;AAgCD,SAjCM,CAAP;AAkCD,KAnCD;AAqCA;;;;AAIApD,eAAAiB,SAAA,CAAAyI,YAAA,GAAA,UAAarB,KAAb,EAAyB;AAAzB,YAAAlH,QAAA,IAAA;AACE,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,eAAhC,EAAiD,UAAAC,GAAA,EAAG;AACzD,mBAAOF,MAAKJ,cAAL,CAAoB4I,yBAApB,CAA8CtI,GAA9C,EAAmDgH,KAAnD,CAAP;AACD,SAFM,CAAP;AAGD,KAJD;AAMA;;;;AAIArI,eAAAiB,SAAA,CAAA2I,kBAAA,GAAA,UAAmB7G,QAAnB,EAAqC;AAArC,YAAA5B,QAAA,IAAA;AACE,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,sBAAhC,EAAwD,UAAAC,GAAA,EAAG;AAChE,mBAAOF,MAAKN,UAAL,CAAgBgJ,0BAAhB,CAA2CxI,GAA3C,EAAgD0B,QAAhD,CAAP;AACD,SAFM,CAAP;AAGD,KAJD;AAMA;;;;;;AAMA/C,eAAAiB,SAAA,CAAA6I,cAAA,GAAA,YAAA;AAAA,YAAA3I,QAAA,IAAA;AACE;AACA;AACA,eAAO,KAAKlB,WAAL,CAAiBmB,cAAjB,CAAgC,oBAAhC,EAAsD,UAAAC,GAAA,EAAG;AAC9D,mBAAOF,MAAKhB,gBAAL,CAAsB2J,cAAtB,CAAqCzI,GAArC,EAA0CE,IAA1C,CAA+C,UAAAwI,OAAA,EAAO;AAC3D,oBAAMtE,WAAW,EAAjB;AACAsE,wBAAQlD,OAAR,CAAgB,UAAAhE,GAAA,EAAG;AACjB4C,6BAASnB,IAAT,CAAcnD,MAAKR,eAAL,CAAqBqJ,WAArB,CAAiC3I,GAAjC,EAAsCwB,GAAtC,CAAd;AACD,iBAFD;AAGA,uBAAO,wCAAmB+E,OAAnB,CAA2BnC,QAA3B,CAAP;AACD,aANM,CAAP;AAOD,SARM,CAAP;AASD,KAZD;AAcQzF,eAAAiB,SAAA,CAAA4G,uBAAA,GAAR,UACExG,GADF,EAEEmE,cAFF,EAE4C;AAE1C,YAAMyE,YAAmC,EAAzC;AACA,aAA0B,IAAAhI,KAAA,CAAA,EAAAC,KAAA,KAAK1B,gBAA/B,EAA0ByB,KAAAC,GAAAC,MAA1B,EAA0BF,IAA1B,EAA+C;AAA1C,gBAAMgC,cAAW/B,GAAAD,EAAA,CAAjB;AACH,gBAAI,CAAC,KAAKiI,mBAAL,CAAyBjG,YAAYI,aAArC,CAAL,EAA0D;AACxD;AACD;AACD4F,sBAAU3F,IAAV,CAAeL,WAAf;AACD;AAED,YAAIgG,UAAU9H,MAAV,KAAqB,CAAzB,EAA4B;AAC1B,mBAAO,wCAAmBiB,OAAnB,CAA2B,kCAA3B,CAAP;AACD,SAFD,MAEO;AACL,iBAAK5C,gBAAL,CAAsB2J,MAAtB,CAA6B,CAA7B,EAAgCF,UAAU9H,MAA1C;AACA,mBAAO,KAAKqC,mBAAL,CAAyBnD,GAAzB,EAA8B4I,SAA9B,EAAyCzE,cAAzC,CAAP;AACD;AACF,KAlBO;AAoBAxF,eAAAiB,SAAA,CAAAiJ,mBAAA,GAAR,UAA4BjD,OAA5B,EAAoD;AAClD;AACA;AACA,YAAMO,oBAAoB,KAAK3G,UAAL,CAAgBwE,4BAAhB,EAA1B;AACA,eACE4B,QAAQG,SAAR,CAAkBI,iBAAlB,KAAwC,CAAxC,IACA1H,SAAS0J,OAAT,CAAiB,KAAKnJ,SAAtB,CAFF;AAID,KARO;AAUAL,eAAAiB,SAAA,CAAAmD,qBAAA,GAAR,UAA8B6C,OAA9B,EAAsD;AACpD;AACA,eACE,CAAC,KAAKiD,mBAAL,CAAyBjD,OAAzB,CAAD,IAAsC,KAAKzG,gBAAL,CAAsB2B,MAAtB,GAA+B,CADvE;AAGD,KALO;AAOAnC,eAAAiB,SAAA,CAAAuD,mBAAA,GAAR,UACEnD,GADF,EAEE+I,YAFF,EAGE5E,cAHF,EAG4C;AAH5C,YAAArE,QAAA,IAAA;AAKE,YAAIkJ,eAAe,wCAAmBjH,OAAnB,EAAnB;ACpJI,YAAIkH,UAAU,SAAVA,OAAU,CDqJPrG,WCrJO,EDqJI;AACpBoG,2BAAeA,aAAa9I,IAAb,CAAkB,YAAA;AAC/B,uBAAAJ,MAAKoJ,2BAAL,CAAiClJ,GAAjC,EAAsC4C,WAAtC,EAAmDuB,cAAnD,CAAA;AAAkE,aADrD,CAAf;AAGD,SCzJG;ADqJJ,aAA0B,IAAAvD,KAAA,CAAA,EAAAuI,iBAAAJ,YAA1B,EAA0BnI,KAAAuI,eAAArI,MAA1B,EAA0BF,IAA1B,EAAsC;AAAjC,gBAAMgC,cAAWuG,eAAAvI,EAAA,CAAjB;AC9IGqI,oBD8IGrG,WC9IH;ADkJP;AACD,eAAOoG,aAAa9I,IAAb,CAAkB,YAAA;AACvB,mBAAOJ,MAAKmC,qBAAL,CACLjC,GADK,EAEL+I,aAAaK,GAAb,CAAiB,UAAAC,MAAA,EAAM;AAAI,uBAAAA,OAAOnI,KAAP;AAAY,aAAvC,CAFK,CAAP;AAID,SALM,CAAP;AAMD,KAjBO;AAmBAvC,eAAAiB,SAAA,CAAAiE,mBAAA,GAAR,UACE7D,GADF,EAEEkB,KAFF,EAEsB;AAEpB,eAAO,KAAKe,qBAAL,CAA2BjC,GAA3B,EAAgC,CAACkB,KAAD,CAAhC,CAAP;AACD,KALO;AAOR;AACQvC,eAAAiB,SAAA,CAAAqC,qBAAA,GAAR,UACEjC,GADF,EAEEe,OAFF,EAE0B;AAExB,YAAIuI,eAAe,kCAAnB;AACA,aAAoB,IAAA1I,KAAA,CAAA,EAAA2I,YAAAxI,OAApB,EAAoBH,KAAA2I,UAAAzI,MAApB,EAAoBF,IAApB,EAA2B;AAAtB,gBAAMM,QAAKqI,UAAA3I,EAAA,CAAX;AACH,iBAAuB,IAAAC,KAAA,CAAA,EAAAG,KAAAE,MAAMG,SAA7B,EAAuBR,KAAAG,GAAAF,MAAvB,EAAuBD,IAAvB,EAAsC;AAAjC,oBAAMS,WAAQN,GAAAH,EAAA,CAAd;AACH,oBAAMW,MAAMF,SAASE,GAArB;AACA8H,+BAAeA,aAAa/H,GAAb,CAAiBC,GAAjB,CAAf;AACD;AACF;AAED,eAAO,KAAKpC,aAAL,CACJ6C,qBADI,CACkBjC,GADlB,EACuBe,OADvB,EAEJb,IAFI,CAEC,YAAA;AAAM,mBAAAoJ,YAAA;AAAY,SAFnB,CAAP;AAGD,KAfO;AAiBA3K,eAAAiB,SAAA,CAAAsJ,2BAAA,GAAR,UACElJ,GADF,EAEE4C,WAFF,EAGEuB,cAHF,EAG4C;AAE1C,YAAMjD,QAAQ0B,YAAY1B,KAA1B;AACA,YAAMsI,UAAUtI,MAAMqB,IAAN,EAAhB;AACA,YAAIyG,eAAe,wCAAmBjH,OAAnB,EAAnB;AACAyH,gBAAQhE,OAAR,CAAgB,UAAAiE,MAAA,EAAM;AACpBT,2BAAeA,aACZ9I,IADY,CACP,YAAA;AACJ,uBAAOiE,eAAeuB,QAAf,CAAwB1F,GAAxB,EAA6ByJ,MAA7B,CAAP;AACD,aAHY,EAIZvJ,IAJY,CAIP,UAACwJ,SAAD,EAAgC;AACpC,oBAAIjE,MAAMiE,SAAV;AACA,oBAAMC,aAAa/G,YAAYgH,WAAZ,CAAwBC,GAAxB,CAA4BJ,MAA5B,CAAnB;AACA,oCACEE,eAAe,IADjB,EAEE,oDAFF;AAIA,oBAAI,CAAClE,GAAD,IAAQA,IAAIG,OAAJ,CAAYG,SAAZ,CAAsB4D,UAAtB,IAAqC,CAAjD,EAAoD;AAClDlE,0BAAMvE,MAAM4I,qBAAN,CAA4BL,MAA5B,EAAoChE,GAApC,EAAyC7C,WAAzC,CAAN;AACA,wBAAI,CAAC6C,GAAL,EAAU;AACR,4CACE,CAACiE,SADH,EAEE,oBACExI,KADF,GAEE,uBAFF,GAGEwI,SAHF,GAIE,mBANJ;AAQD,qBATD,MASO;AACLvF,uCAAe6B,QAAf,CAAwBP,GAAxB;AACD;AACF;AACF,aA1BY,CAAf;AA2BD,SA5BD;AA6BA,eAAOuD,YAAP;AACD,KAtCO;AAuCV,WAAArK,UAAA;AArtBA,CAAA,EAAA;QCkjBSA,U,GAAAA,U","file":"local_store.js","sourcesContent":["/**\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { User } from '../auth/user';\nimport { Query } from '../core/query';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { TargetIdGenerator } from '../core/target_id_generator';\nimport { Timestamp } from '../core/timestamp';\nimport { BatchId, ProtoByteString, TargetId } from '../core/types';\nimport {\n  DocumentKeySet,\n  documentKeySet,\n  DocumentMap,\n  MaybeDocumentMap\n} from '../model/collections';\nimport { MaybeDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { Mutation } from '../model/mutation';\nimport {\n  BATCHID_UNKNOWN,\n  MutationBatch,\n  MutationBatchResult\n} from '../model/mutation_batch';\nimport {\n  RemoteEvent,\n  ResetMapping,\n  TargetChange,\n  UpdateMapping\n} from '../remote/remote_event';\nimport { assert, fail } from '../util/assert';\nimport * as log from '../util/log';\nimport * as objUtils from '../util/obj';\nimport { PromiseImpl as Promise } from '../../utils/promise';\n\nimport { GarbageCollector } from './garbage_collector';\nimport { LocalDocumentsView } from './local_documents_view';\nimport { LocalViewChanges } from './local_view_changes';\nimport { MutationQueue } from './mutation_queue';\nimport { Persistence, PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { QueryCache } from './query_cache';\nimport { QueryData, QueryPurpose } from './query_data';\nimport { ReferenceSet } from './reference_set';\nimport { RemoteDocumentCache } from './remote_document_cache';\nimport { RemoteDocumentChangeBuffer } from './remote_document_change_buffer';\n\nconst LOG_TAG = 'LocalStore';\n\n/** The result of a write to the local store. */\nexport interface LocalWriteResult {\n  batchId: BatchId;\n  changes: MaybeDocumentMap;\n}\n\n/**\n * Local storage in the Firestore client. Coordinates persistence components\n * like the mutation queue and remote document cache to present a\n * latency-compensated view of stored data.\n *\n * The LocalStore is responsible for accepting mutations from the Sync Engine.\n * Writes from the client are put into a queue as provisional Mutations until\n * they are processed by the RemoteStore and confirmed as having been written\n * to the server.\n *\n * The local store provides the local version of documents that have been\n * modified locally. It maintains the constraint:\n *\n *   LocalDocument = RemoteDocument + Active(LocalMutations)\n *\n * (Active mutations are those that are enqueued and have not been previously\n * acknowledged or rejected).\n *\n * The RemoteDocument (\"ground truth\") state is provided via the\n * applyChangeBatch method. It will be some version of a server-provided\n * document OR will be a server-provided document PLUS acknowledged mutations:\n *\n *   RemoteDocument' = RemoteDocument + Acknowledged(LocalMutations)\n *\n * Note that this \"dirty\" version of a RemoteDocument will not be identical to a\n * server base version, since it has LocalMutations added to it pending getting\n * an authoritative copy from the server.\n *\n * Since LocalMutations can be rejected by the server, we have to be able to\n * revert a LocalMutation that has already been applied to the LocalDocument\n * (typically done by replaying all remaining LocalMutations to the\n * RemoteDocument to re-apply).\n *\n * The LocalStore is responsible for the garbage collection of the documents it\n * contains. For now, it every doc referenced by a view, the mutation queue, or\n * the RemoteStore.\n *\n * It also maintains the persistence of mapping queries to resume tokens and\n * target ids. It needs to know this data about queries to properly know what\n * docs it would be allowed to garbage collect.\n *\n * The LocalStore must be able to efficiently execute queries against its local\n * cache of the documents, to provide the initial set of results before any\n * remote changes have been received.\n *\n * Note: In TypeScript, most methods return Promises since the implementation\n * may rely on fetching data from IndexedDB which is async.\n * These Promises will only be rejected on an I/O error or other internal\n * (unexpected) failure (e.g. failed assert) and always represent an\n * unrecoverable error (should be caught / reported by the async_queue).\n */\nexport class LocalStore {\n  /**\n   * The set of all mutations that have been sent but not yet been applied to\n   * the backend.\n   */\n  private mutationQueue: MutationQueue;\n\n  /** The set of all cached remote documents. */\n  private remoteDocuments: RemoteDocumentCache;\n\n  /**\n   * The \"local\" view of all documents (layering mutationQueue on top of\n   * remoteDocumentCache).\n   */\n  private localDocuments: LocalDocumentsView;\n\n  /**\n   * The set of document references maintained by any local views.\n   */\n  private localViewReferences = new ReferenceSet();\n\n  /** Maps a query to the data about that query. */\n  private queryCache: QueryCache;\n\n  /** Maps a targetID to data about its query. */\n  private targetIds = {} as { [targetId: number]: QueryData };\n\n  /** Used to generate targetIDs for queries tracked locally. */\n  private targetIdGenerator = TargetIdGenerator.forLocalStore();\n\n  /**\n   * A heldBatchResult is a mutation batch result (from a write acknowledgement)\n   * that arrived before the watch stream got notified of a snapshot that\n   * includes the write. So we \"hold\" it until the watch stream catches up. It\n   * ensures that the local write remains visible (latency compensation) and\n   * doesn't temporarily appear reverted because the watch stream is slower than\n   * the write stream and so wasn't reflecting it.\n   *\n   * NOTE: Eventually we want to move this functionality into the remote store.\n   */\n  private heldBatchResults: MutationBatchResult[] = [];\n\n  constructor(\n    /** Manages our in-memory or durable persistence. */\n    private persistence: Persistence,\n    initialUser: User,\n    /**\n       * The garbage collector collects documents that should no longer be\n       * cached (e.g. if they are no longer retained by the above reference sets\n       * and the garbage collector is performing eager collection).\n       */\n    private garbageCollector: GarbageCollector\n  ) {\n    this.mutationQueue = persistence.getMutationQueue(initialUser);\n    this.remoteDocuments = persistence.getRemoteDocumentCache();\n    this.queryCache = persistence.getQueryCache();\n    this.localDocuments = new LocalDocumentsView(\n      this.remoteDocuments,\n      this.mutationQueue\n    );\n    this.garbageCollector.addGarbageSource(this.localViewReferences);\n    this.garbageCollector.addGarbageSource(this.queryCache);\n    this.garbageCollector.addGarbageSource(this.mutationQueue);\n  }\n\n  /** Performs any initial startup actions required by the local store. */\n  start(): Promise<void> {\n    return this.persistence.runTransaction('Start LocalStore', txn => {\n      return this.startMutationQueue(txn).next(() => this.startQueryCache(txn));\n    });\n  }\n\n  /**\n   * Tells the LocalStore that the currently authenticated user has changed.\n   *\n   * In response the local store switches the mutation queue to the new user and\n   * returns any resulting document changes.\n   */\n  handleUserChange(user: User): Promise<MaybeDocumentMap> {\n    return this.persistence.runTransaction('Handle user change', txn => {\n      // Swap out the mutation queue, grabbing the pending mutation batches\n      // before and after.\n      let oldBatches: MutationBatch[];\n      return this.mutationQueue\n        .getAllMutationBatches(txn)\n        .next(promisedOldBatches => {\n          oldBatches = promisedOldBatches;\n\n          this.garbageCollector.removeGarbageSource(this.mutationQueue);\n          this.mutationQueue = this.persistence.getMutationQueue(user);\n          this.garbageCollector.addGarbageSource(this.mutationQueue);\n          return this.startMutationQueue(txn);\n        })\n        .next(() => {\n          // Recreate our LocalDocumentsView using the new\n          // MutationQueue.\n          this.localDocuments = new LocalDocumentsView(\n            this.remoteDocuments,\n            this.mutationQueue\n          );\n          return this.mutationQueue.getAllMutationBatches(txn);\n        })\n        .next(newBatches => {\n          // Union the old/new changed keys.\n          let changedKeys = documentKeySet();\n          for (const batches of [oldBatches, newBatches]) {\n            for (const batch of batches) {\n              for (const mutation of batch.mutations) {\n                changedKeys = changedKeys.add(mutation.key);\n              }\n            }\n          }\n\n          // Return the set of all (potentially) changed documents as the\n          // result of the user change.\n          return this.localDocuments.getDocuments(txn, changedKeys);\n        });\n    });\n  }\n\n  private startQueryCache(\n    txn: PersistenceTransaction\n  ): PersistencePromise<void> {\n    return this.queryCache.start(txn).next(() => {\n      const targetId = this.queryCache.getHighestTargetId();\n      this.targetIdGenerator = TargetIdGenerator.forLocalStore(targetId);\n    });\n  }\n\n  private startMutationQueue(\n    txn: PersistenceTransaction\n  ): PersistencePromise<void> {\n    return this.mutationQueue\n      .start(txn)\n      .next(() => {\n        // If we have any leftover mutation batch results from a prior run,\n        // just drop them.\n        // TODO(http://b/33446471): We probably need to repopulate\n        // heldBatchResults or similar instead, but that is not\n        // straightforward since we're not persisting the write ack versions.\n        this.heldBatchResults = [];\n        return this.mutationQueue.getHighestAcknowledgedBatchId(txn);\n      })\n      .next(highestAck => {\n        // TODO(mikelehen): This is the only usage of\n        // getAllMutationBatchesThroughBatchId(). Consider removing it in\n        // favor of a getAcknowledgedBatches() method.\n        if (highestAck !== BATCHID_UNKNOWN) {\n          return this.mutationQueue.getAllMutationBatchesThroughBatchId(\n            txn,\n            highestAck\n          );\n        } else {\n          return PersistencePromise.resolve([]);\n        }\n      })\n      .next(ackedBatches => {\n        if (ackedBatches.length > 0) {\n          return this.mutationQueue.removeMutationBatches(txn, ackedBatches);\n        } else {\n          return PersistencePromise.resolve();\n        }\n      });\n  }\n\n  /* Accept locally generated Mutations and commit them to storage. */\n  localWrite(mutations: Mutation[]): Promise<LocalWriteResult> {\n    return this.persistence.runTransaction('Locally write mutations', txn => {\n      let batch: MutationBatch;\n      const localWriteTime = Timestamp.now();\n      return this.mutationQueue\n        .addMutationBatch(txn, localWriteTime, mutations)\n        .next(promisedBatch => {\n          batch = promisedBatch;\n          // TODO(koss): This is doing an N^2 update by replaying ALL the\n          // mutations on each document (instead of just the ones added) in\n          // this batch.\n          const keys = batch.keys();\n          return this.localDocuments.getDocuments(txn, keys);\n        })\n        .next((changedDocuments: MaybeDocumentMap) => {\n          return { batchId: batch.batchId, changes: changedDocuments };\n        });\n    });\n  }\n\n  /**\n   * Acknowledge the given batch.\n   *\n   * On the happy path when a batch is acknowledged, the local store will\n   *\n   *  + remove the batch from the mutation queue;\n   *  + apply the changes to the remote document cache;\n   *  + recalculate the latency compensated view implied by those changes (there\n   *    may be mutations in the queue that affect the documents but haven't been\n   *    acknowledged yet); and\n   *  + give the changed documents back the sync engine\n   *\n   * @returns The resulting (modified) documents.\n   */\n  acknowledgeBatch(\n    batchResult: MutationBatchResult\n  ): Promise<MaybeDocumentMap> {\n    return this.persistence.runTransaction('Acknowledge batch', txn => {\n      let affected: DocumentKeySet;\n      return this.mutationQueue\n        .acknowledgeBatch(txn, batchResult.batch, batchResult.streamToken)\n        .next(() => {\n          if (this.shouldHoldBatchResult(batchResult.commitVersion)) {\n            this.heldBatchResults.push(batchResult);\n            affected = documentKeySet();\n            return PersistencePromise.resolve();\n          } else {\n            const documentBuffer = new RemoteDocumentChangeBuffer(\n              this.remoteDocuments\n            );\n            return this.releaseBatchResults(\n              txn,\n              [batchResult],\n              documentBuffer\n            ).next(promisedAffectedKeys => {\n              affected = promisedAffectedKeys;\n              return documentBuffer.apply(txn);\n            });\n          }\n        })\n        .next(() => {\n          return this.mutationQueue.performConsistencyCheck(txn);\n        })\n        .next(() => {\n          return this.localDocuments.getDocuments(txn, affected);\n        });\n    });\n  }\n\n  /**\n   * Remove mutations from the MutationQueue for the specified batch;\n   * LocalDocuments will be recalculated.\n   *\n   * @returns The resulting modified documents.\n   */\n  rejectBatch(batchId: BatchId): Promise<MaybeDocumentMap> {\n    return this.persistence.runTransaction('Reject batch', txn => {\n      let toReject: MutationBatch;\n      let affectedKeys: DocumentKeySet;\n      return this.mutationQueue\n        .lookupMutationBatch(txn, batchId)\n        .next((promisedToReject: MutationBatch | null) => {\n          assert(\n            promisedToReject != null,\n            'Attempt to reject nonexistent batch!'\n          );\n          toReject = promisedToReject!;\n\n          return this.mutationQueue\n            .getHighestAcknowledgedBatchId(txn)\n            .next(lastAcked => {\n              assert(\n                batchId > lastAcked,\n                \"Acknowledged batches can't be rejected.\"\n              );\n              return toReject;\n            });\n        })\n        .next(() => {\n          return this.removeMutationBatch(txn, toReject);\n        })\n        .next(promisedAffectedKeys => {\n          affectedKeys = promisedAffectedKeys;\n          return this.mutationQueue.performConsistencyCheck(txn);\n        })\n        .next(() => {\n          return this.localDocuments.getDocuments(txn, affectedKeys);\n        });\n    });\n  }\n\n  /** Returns the last recorded stream token for the current user. */\n  getLastStreamToken(): Promise<ProtoByteString> {\n    return this.persistence.runTransaction('Get last stream token', txn => {\n      return this.mutationQueue.getLastStreamToken(txn);\n    });\n  }\n\n  /**\n   * Sets the stream token for the current user without acknowledging any\n   * mutation batch. This is usually only useful after a stream handshake or in\n   * response to an error that requires clearing the stream token.\n   */\n  setLastStreamToken(streamToken: ProtoByteString): Promise<void> {\n    return this.persistence.runTransaction('Set last stream token', txn => {\n      return this.mutationQueue.setLastStreamToken(txn, streamToken);\n    });\n  }\n\n  /**\n   * Returns the last consistent snapshot processed (used by the RemoteStore to\n   * determine whether to buffer incoming snapshots from the backend).\n   */\n  getLastRemoteSnapshotVersion(): SnapshotVersion {\n    return this.queryCache.getLastRemoteSnapshotVersion();\n  }\n\n  /**\n   * Update the \"ground-state\" (remote) documents. We assume that the remote\n   * event reflects any write batches that have been acknowledged or rejected\n   * (i.e. we do not re-apply local mutations to updates from this event).\n   *\n   * LocalDocuments are re-calculated if there are remaining mutations in the\n   * queue.\n   */\n  applyRemoteEvent(remoteEvent: RemoteEvent): Promise<MaybeDocumentMap> {\n    const documentBuffer = new RemoteDocumentChangeBuffer(this.remoteDocuments);\n    return this.persistence.runTransaction('Apply remote event', txn => {\n      const promises = [] as Array<PersistencePromise<void>>;\n      objUtils.forEachNumber(\n        remoteEvent.targetChanges,\n        (targetId: TargetId, change: TargetChange) => {\n          // Do not ref/unref unassigned targetIds - it may lead to leaks.\n          let queryData = this.targetIds[targetId];\n          if (!queryData) return;\n\n          const mapping: UpdateMapping | ResetMapping = change.mapping;\n          if (mapping) {\n            // First make sure that all references are deleted\n            if (mapping instanceof ResetMapping) {\n              promises.push(\n                this.queryCache\n                  .removeMatchingKeysForTargetId(txn, targetId)\n                  .next(() => {\n                    return this.queryCache.addMatchingKeys(\n                      txn,\n                      mapping.documents,\n                      targetId\n                    );\n                  })\n              );\n            } else if (mapping instanceof UpdateMapping) {\n              promises.push(\n                this.queryCache\n                  .removeMatchingKeys(txn, mapping.removedDocuments, targetId)\n                  .next(() => {\n                    return this.queryCache.addMatchingKeys(\n                      txn,\n                      mapping.addedDocuments,\n                      targetId\n                    );\n                  })\n              );\n            } else {\n              return fail('Unknown mapping type: ' + JSON.stringify(mapping));\n            }\n          }\n\n          // Update the resume token if the change includes one. Don't clear\n          // any preexisting value.\n          const resumeToken = change.resumeToken;\n          if (resumeToken.length > 0) {\n            queryData = queryData.update({\n              resumeToken,\n              snapshotVersion: change.snapshotVersion\n            });\n            this.targetIds[targetId] = queryData;\n            promises.push(this.queryCache.addQueryData(txn, queryData));\n          }\n        }\n      );\n\n      let changedDocKeys = documentKeySet();\n      remoteEvent.documentUpdates.forEach((key, doc) => {\n        changedDocKeys = changedDocKeys.add(key);\n        promises.push(\n          documentBuffer.getEntry(txn, key).next(existingDoc => {\n            // Make sure we don't apply an old document version to the remote\n            // cache, though we make an exception for SnapshotVersion.MIN which\n            // can happen for manufactured events (e.g. in the case of a limbo\n            // document resolution failing).\n            if (\n              existingDoc == null ||\n              doc.version.equals(SnapshotVersion.MIN) ||\n              doc.version.compareTo(existingDoc.version) >= 0\n            ) {\n              documentBuffer.addEntry(doc);\n            } else {\n              log.debug(\n                LOG_TAG,\n                'Ignoring outdated watch update for ',\n                key,\n                '. Current version:',\n                existingDoc.version,\n                ' Watch version:',\n                doc.version\n              );\n            }\n\n            // The document might be garbage because it was unreferenced by\n            // everything. Make sure to mark it as garbage if it is...\n            this.garbageCollector.addPotentialGarbageKey(key);\n          })\n        );\n      });\n\n      // HACK: The only reason we allow a null snapshot version is so that we\n      // can synthesize remote events when we get permission denied errors while\n      // trying to resolve the state of a locally cached document that is in\n      // limbo.\n      const lastRemoteVersion = this.queryCache.getLastRemoteSnapshotVersion();\n      const remoteVersion = remoteEvent.snapshotVersion;\n      if (!remoteVersion.equals(SnapshotVersion.MIN)) {\n        assert(\n          remoteVersion.compareTo(lastRemoteVersion) >= 0,\n          'Watch stream reverted to previous snapshot?? ' +\n            remoteVersion +\n            ' < ' +\n            lastRemoteVersion\n        );\n        promises.push(\n          this.queryCache.setLastRemoteSnapshotVersion(txn, remoteVersion)\n        );\n      }\n\n      let releasedWriteKeys: DocumentKeySet;\n      return PersistencePromise.waitFor(promises)\n        .next(() => this.releaseHeldBatchResults(txn, documentBuffer))\n        .next(promisedReleasedWriteKeys => {\n          releasedWriteKeys = promisedReleasedWriteKeys;\n          return documentBuffer.apply(txn);\n        })\n        .next(() => {\n          return this.localDocuments.getDocuments(\n            txn,\n            changedDocKeys.unionWith(releasedWriteKeys)\n          );\n        });\n    });\n  }\n\n  /**\n   * Notify local store of the changed views to locally pin documents.\n   */\n  notifyLocalViewChanges(viewChanges: LocalViewChanges[]): Promise<void> {\n    return this.persistence.runTransaction('Notify local view changes', txn => {\n      const promises = [] as Array<PersistencePromise<void>>;\n      for (const view of viewChanges) {\n        promises.push(\n          this.queryCache\n            .getQueryData(txn, view.query)\n            .next((queryData: QueryData | null) => {\n              assert(\n                queryData !== null,\n                'Local view changes contain unallocated query.'\n              );\n              const targetId = queryData!.targetId;\n              this.localViewReferences.addReferences(view.addedKeys, targetId);\n              this.localViewReferences.removeReferences(\n                view.removedKeys,\n                targetId\n              );\n            })\n        );\n      }\n      return PersistencePromise.waitFor(promises);\n    });\n  }\n\n  /**\n   * Gets the mutation batch after the passed in batchId in the mutation queue\n   *  or null if empty.\n   *  @param afterBatchId If provided, the batch to search after.\n   *  @returns The next mutation or null if there wasn't one.\n   */\n  nextMutationBatch(afterBatchId?: BatchId): Promise<MutationBatch | null> {\n    return this.persistence.runTransaction('Get next mutation batch', txn => {\n      if (afterBatchId === undefined) {\n        afterBatchId = BATCHID_UNKNOWN;\n      }\n      return this.mutationQueue.getNextMutationBatchAfterBatchId(\n        txn,\n        afterBatchId\n      );\n    });\n  }\n\n  /**\n   * Read the current value of a Document with a given key or null if not\n   * found - used for testing.\n   */\n  readDocument(key: DocumentKey): Promise<MaybeDocument | null> {\n    return this.persistence.runTransaction('read document', txn => {\n      return this.localDocuments.getDocument(txn, key);\n    });\n  }\n\n  /**\n   * Assigns the given query an internal ID so that its results can be pinned so\n   * they don't get GC'd. A query must be allocated in the local store before\n   * the store can be used to manage its view.\n   */\n  allocateQuery(query: Query): Promise<QueryData> {\n    return this.persistence.runTransaction('Allocate query', txn => {\n      let queryData: QueryData;\n      return this.queryCache\n        .getQueryData(txn, query)\n        .next((cached: QueryData | null) => {\n          if (cached) {\n            // This query has been listened to previously, so reuse the\n            // previous targetID.\n            // TODO(mcg): freshen last accessed date?\n            queryData = cached;\n            return PersistencePromise.resolve();\n          } else {\n            const targetId = this.targetIdGenerator.next();\n            queryData = new QueryData(query, targetId, QueryPurpose.Listen);\n            return this.queryCache.addQueryData(txn, queryData);\n          }\n        })\n        .next(() => {\n          assert(\n            !this.targetIds[queryData.targetId],\n            'Tried to allocate an already allocated query: ' + query\n          );\n          this.targetIds[queryData.targetId] = queryData;\n          return queryData;\n        });\n    });\n  }\n\n  /** Unpin all the documents associated with the given query. */\n  releaseQuery(query: Query): Promise<void> {\n    return this.persistence.runTransaction('Release query', txn => {\n      return this.queryCache\n        .getQueryData(txn, query)\n        .next((queryData: QueryData | null) => {\n          assert(\n            queryData != null,\n            'Tried to release nonexistent query: ' + query\n          );\n          this.localViewReferences.removeReferencesForId(queryData!.targetId);\n          delete this.targetIds[queryData!.targetId];\n          if (this.garbageCollector.isEager) {\n            return this.queryCache.removeQueryData(txn, queryData!);\n          } else {\n            return PersistencePromise.resolve();\n          }\n        })\n        .next(() => {\n          // If this was the last watch target, then we won't get any more\n          // watch snapshots, so we should release any held batch results.\n          if (objUtils.isEmpty(this.targetIds)) {\n            const documentBuffer = new RemoteDocumentChangeBuffer(\n              this.remoteDocuments\n            );\n            return this.releaseHeldBatchResults(\n              txn,\n              documentBuffer\n            ).next(() => {\n              documentBuffer.apply(txn);\n            });\n          } else {\n            return PersistencePromise.resolve();\n          }\n        });\n    });\n  }\n\n  /**\n   * Runs the specified query against all the documents in the local store and\n   * returns the results.\n   */\n  executeQuery(query: Query): Promise<DocumentMap> {\n    return this.persistence.runTransaction('Execute query', txn => {\n      return this.localDocuments.getDocumentsMatchingQuery(txn, query);\n    });\n  }\n\n  /**\n   * Returns the keys of the documents that are associated with the given\n   * target id in the remote table.\n   */\n  remoteDocumentKeys(targetId: TargetId): Promise<DocumentKeySet> {\n    return this.persistence.runTransaction('Remote document keys', txn => {\n      return this.queryCache.getMatchingKeysForTargetId(txn, targetId);\n    });\n  }\n\n  /**\n   * Collect garbage if necessary.\n   * Should be called periodically by Sync Engine to recover resources. The\n   * implementation must guarantee that GC won't happen in other places than\n   * this method call.\n   */\n  collectGarbage(): Promise<void> {\n    // Call collectGarbage regardless of whether isGCEnabled so the referenceSet\n    // doesn't continue to accumulate the garbage keys.\n    return this.persistence.runTransaction('Garbage collection', txn => {\n      return this.garbageCollector.collectGarbage(txn).next(garbage => {\n        const promises = [] as Array<PersistencePromise<void>>;\n        garbage.forEach(key => {\n          promises.push(this.remoteDocuments.removeEntry(txn, key));\n        });\n        return PersistencePromise.waitFor(promises);\n      });\n    });\n  }\n\n  private releaseHeldBatchResults(\n    txn: PersistenceTransaction,\n    documentBuffer: RemoteDocumentChangeBuffer\n  ): PersistencePromise<DocumentKeySet> {\n    const toRelease: MutationBatchResult[] = [];\n    for (const batchResult of this.heldBatchResults) {\n      if (!this.isRemoteUpToVersion(batchResult.commitVersion)) {\n        break;\n      }\n      toRelease.push(batchResult);\n    }\n\n    if (toRelease.length === 0) {\n      return PersistencePromise.resolve(documentKeySet());\n    } else {\n      this.heldBatchResults.splice(0, toRelease.length);\n      return this.releaseBatchResults(txn, toRelease, documentBuffer);\n    }\n  }\n\n  private isRemoteUpToVersion(version: SnapshotVersion): boolean {\n    // If there are no watch targets, then we won't get remote snapshots, and\n    // we are always \"up-to-date.\"\n    const lastRemoteVersion = this.queryCache.getLastRemoteSnapshotVersion();\n    return (\n      version.compareTo(lastRemoteVersion) <= 0 ||\n      objUtils.isEmpty(this.targetIds)\n    );\n  }\n\n  private shouldHoldBatchResult(version: SnapshotVersion): boolean {\n    // Check if watcher isn't up to date or prior results are already held.\n    return (\n      !this.isRemoteUpToVersion(version) || this.heldBatchResults.length > 0\n    );\n  }\n\n  private releaseBatchResults(\n    txn: PersistenceTransaction,\n    batchResults: MutationBatchResult[],\n    documentBuffer: RemoteDocumentChangeBuffer\n  ): PersistencePromise<DocumentKeySet> {\n    let promiseChain = PersistencePromise.resolve();\n    for (const batchResult of batchResults) {\n      promiseChain = promiseChain.next(() =>\n        this.applyWriteToRemoteDocuments(txn, batchResult, documentBuffer)\n      );\n    }\n    return promiseChain.next(() => {\n      return this.removeMutationBatches(\n        txn,\n        batchResults.map(result => result.batch)\n      );\n    });\n  }\n\n  private removeMutationBatch(\n    txn: PersistenceTransaction,\n    batch: MutationBatch\n  ): PersistencePromise<DocumentKeySet> {\n    return this.removeMutationBatches(txn, [batch]);\n  }\n\n  /** Removes all the mutation batches named in the given array. */\n  private removeMutationBatches(\n    txn: PersistenceTransaction,\n    batches: MutationBatch[]\n  ): PersistencePromise<DocumentKeySet> {\n    let affectedDocs = documentKeySet();\n    for (const batch of batches) {\n      for (const mutation of batch.mutations) {\n        const key = mutation.key;\n        affectedDocs = affectedDocs.add(key);\n      }\n    }\n\n    return this.mutationQueue\n      .removeMutationBatches(txn, batches)\n      .next(() => affectedDocs);\n  }\n\n  private applyWriteToRemoteDocuments(\n    txn: PersistenceTransaction,\n    batchResult: MutationBatchResult,\n    documentBuffer: RemoteDocumentChangeBuffer\n  ): PersistencePromise<void> {\n    const batch = batchResult.batch;\n    const docKeys = batch.keys();\n    let promiseChain = PersistencePromise.resolve();\n    docKeys.forEach(docKey => {\n      promiseChain = promiseChain\n        .next(() => {\n          return documentBuffer.getEntry(txn, docKey);\n        })\n        .next((remoteDoc: MaybeDocument | null) => {\n          let doc = remoteDoc;\n          const ackVersion = batchResult.docVersions.get(docKey);\n          assert(\n            ackVersion !== null,\n            'ackVersions should contain every doc in the write.'\n          );\n          if (!doc || doc.version.compareTo(ackVersion!) < 0) {\n            doc = batch.applyToRemoteDocument(docKey, doc, batchResult);\n            if (!doc) {\n              assert(\n                !remoteDoc,\n                'Mutation batch ' +\n                  batch +\n                  ' applied to document ' +\n                  remoteDoc +\n                  ' resulted in null'\n              );\n            } else {\n              documentBuffer.addEntry(doc);\n            }\n          }\n        });\n    });\n    return promiseChain;\n  }\n}\n","/**\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { TargetIdGenerator } from '../core/target_id_generator';\nimport { Timestamp } from '../core/timestamp';\nimport { documentKeySet } from '../model/collections';\nimport { BATCHID_UNKNOWN } from '../model/mutation_batch';\nimport { ResetMapping, UpdateMapping } from '../remote/remote_event';\nimport { assert, fail } from '../util/assert';\nimport * as log from '../util/log';\nimport * as objUtils from '../util/obj';\nimport { LocalDocumentsView } from './local_documents_view';\nimport { PersistencePromise } from './persistence_promise';\nimport { QueryData, QueryPurpose } from './query_data';\nimport { ReferenceSet } from './reference_set';\nimport { RemoteDocumentChangeBuffer } from './remote_document_change_buffer';\nvar LOG_TAG = 'LocalStore';\n/**\n * Local storage in the Firestore client. Coordinates persistence components\n * like the mutation queue and remote document cache to present a\n * latency-compensated view of stored data.\n *\n * The LocalStore is responsible for accepting mutations from the Sync Engine.\n * Writes from the client are put into a queue as provisional Mutations until\n * they are processed by the RemoteStore and confirmed as having been written\n * to the server.\n *\n * The local store provides the local version of documents that have been\n * modified locally. It maintains the constraint:\n *\n *   LocalDocument = RemoteDocument + Active(LocalMutations)\n *\n * (Active mutations are those that are enqueued and have not been previously\n * acknowledged or rejected).\n *\n * The RemoteDocument (\"ground truth\") state is provided via the\n * applyChangeBatch method. It will be some version of a server-provided\n * document OR will be a server-provided document PLUS acknowledged mutations:\n *\n *   RemoteDocument' = RemoteDocument + Acknowledged(LocalMutations)\n *\n * Note that this \"dirty\" version of a RemoteDocument will not be identical to a\n * server base version, since it has LocalMutations added to it pending getting\n * an authoritative copy from the server.\n *\n * Since LocalMutations can be rejected by the server, we have to be able to\n * revert a LocalMutation that has already been applied to the LocalDocument\n * (typically done by replaying all remaining LocalMutations to the\n * RemoteDocument to re-apply).\n *\n * The LocalStore is responsible for the garbage collection of the documents it\n * contains. For now, it every doc referenced by a view, the mutation queue, or\n * the RemoteStore.\n *\n * It also maintains the persistence of mapping queries to resume tokens and\n * target ids. It needs to know this data about queries to properly know what\n * docs it would be allowed to garbage collect.\n *\n * The LocalStore must be able to efficiently execute queries against its local\n * cache of the documents, to provide the initial set of results before any\n * remote changes have been received.\n *\n * Note: In TypeScript, most methods return Promises since the implementation\n * may rely on fetching data from IndexedDB which is async.\n * These Promises will only be rejected on an I/O error or other internal\n * (unexpected) failure (e.g. failed assert) and always represent an\n * unrecoverable error (should be caught / reported by the async_queue).\n */\nvar LocalStore = /** @class */ (function () {\n    function LocalStore(\n        /** Manages our in-memory or durable persistence. */\n        persistence, initialUser, \n        /**\n           * The garbage collector collects documents that should no longer be\n           * cached (e.g. if they are no longer retained by the above reference sets\n           * and the garbage collector is performing eager collection).\n           */\n        garbageCollector) {\n        this.persistence = persistence;\n        this.garbageCollector = garbageCollector;\n        /**\n         * The set of document references maintained by any local views.\n         */\n        this.localViewReferences = new ReferenceSet();\n        /** Maps a targetID to data about its query. */\n        this.targetIds = {};\n        /** Used to generate targetIDs for queries tracked locally. */\n        this.targetIdGenerator = TargetIdGenerator.forLocalStore();\n        /**\n         * A heldBatchResult is a mutation batch result (from a write acknowledgement)\n         * that arrived before the watch stream got notified of a snapshot that\n         * includes the write. So we \"hold\" it until the watch stream catches up. It\n         * ensures that the local write remains visible (latency compensation) and\n         * doesn't temporarily appear reverted because the watch stream is slower than\n         * the write stream and so wasn't reflecting it.\n         *\n         * NOTE: Eventually we want to move this functionality into the remote store.\n         */\n        this.heldBatchResults = [];\n        this.mutationQueue = persistence.getMutationQueue(initialUser);\n        this.remoteDocuments = persistence.getRemoteDocumentCache();\n        this.queryCache = persistence.getQueryCache();\n        this.localDocuments = new LocalDocumentsView(this.remoteDocuments, this.mutationQueue);\n        this.garbageCollector.addGarbageSource(this.localViewReferences);\n        this.garbageCollector.addGarbageSource(this.queryCache);\n        this.garbageCollector.addGarbageSource(this.mutationQueue);\n    }\n    /** Performs any initial startup actions required by the local store. */\n    LocalStore.prototype.start = function () {\n        var _this = this;\n        return this.persistence.runTransaction('Start LocalStore', function (txn) {\n            return _this.startMutationQueue(txn).next(function () { return _this.startQueryCache(txn); });\n        });\n    };\n    /**\n     * Tells the LocalStore that the currently authenticated user has changed.\n     *\n     * In response the local store switches the mutation queue to the new user and\n     * returns any resulting document changes.\n     */\n    LocalStore.prototype.handleUserChange = function (user) {\n        var _this = this;\n        return this.persistence.runTransaction('Handle user change', function (txn) {\n            // Swap out the mutation queue, grabbing the pending mutation batches\n            // before and after.\n            var oldBatches;\n            return _this.mutationQueue\n                .getAllMutationBatches(txn)\n                .next(function (promisedOldBatches) {\n                oldBatches = promisedOldBatches;\n                _this.garbageCollector.removeGarbageSource(_this.mutationQueue);\n                _this.mutationQueue = _this.persistence.getMutationQueue(user);\n                _this.garbageCollector.addGarbageSource(_this.mutationQueue);\n                return _this.startMutationQueue(txn);\n            })\n                .next(function () {\n                // Recreate our LocalDocumentsView using the new\n                // MutationQueue.\n                _this.localDocuments = new LocalDocumentsView(_this.remoteDocuments, _this.mutationQueue);\n                return _this.mutationQueue.getAllMutationBatches(txn);\n            })\n                .next(function (newBatches) {\n                // Union the old/new changed keys.\n                var changedKeys = documentKeySet();\n                for (var _i = 0, _a = [oldBatches, newBatches]; _i < _a.length; _i++) {\n                    var batches = _a[_i];\n                    for (var _b = 0, batches_1 = batches; _b < batches_1.length; _b++) {\n                        var batch = batches_1[_b];\n                        for (var _c = 0, _d = batch.mutations; _c < _d.length; _c++) {\n                            var mutation = _d[_c];\n                            changedKeys = changedKeys.add(mutation.key);\n                        }\n                    }\n                }\n                // Return the set of all (potentially) changed documents as the\n                // result of the user change.\n                return _this.localDocuments.getDocuments(txn, changedKeys);\n            });\n        });\n    };\n    LocalStore.prototype.startQueryCache = function (txn) {\n        var _this = this;\n        return this.queryCache.start(txn).next(function () {\n            var targetId = _this.queryCache.getHighestTargetId();\n            _this.targetIdGenerator = TargetIdGenerator.forLocalStore(targetId);\n        });\n    };\n    LocalStore.prototype.startMutationQueue = function (txn) {\n        var _this = this;\n        return this.mutationQueue\n            .start(txn)\n            .next(function () {\n            // If we have any leftover mutation batch results from a prior run,\n            // just drop them.\n            // TODO(http://b/33446471): We probably need to repopulate\n            // heldBatchResults or similar instead, but that is not\n            // straightforward since we're not persisting the write ack versions.\n            _this.heldBatchResults = [];\n            return _this.mutationQueue.getHighestAcknowledgedBatchId(txn);\n        })\n            .next(function (highestAck) {\n            // TODO(mikelehen): This is the only usage of\n            // getAllMutationBatchesThroughBatchId(). Consider removing it in\n            // favor of a getAcknowledgedBatches() method.\n            if (highestAck !== BATCHID_UNKNOWN) {\n                return _this.mutationQueue.getAllMutationBatchesThroughBatchId(txn, highestAck);\n            }\n            else {\n                return PersistencePromise.resolve([]);\n            }\n        })\n            .next(function (ackedBatches) {\n            if (ackedBatches.length > 0) {\n                return _this.mutationQueue.removeMutationBatches(txn, ackedBatches);\n            }\n            else {\n                return PersistencePromise.resolve();\n            }\n        });\n    };\n    /* Accept locally generated Mutations and commit them to storage. */\n    LocalStore.prototype.localWrite = function (mutations) {\n        var _this = this;\n        return this.persistence.runTransaction('Locally write mutations', function (txn) {\n            var batch;\n            var localWriteTime = Timestamp.now();\n            return _this.mutationQueue\n                .addMutationBatch(txn, localWriteTime, mutations)\n                .next(function (promisedBatch) {\n                batch = promisedBatch;\n                // TODO(koss): This is doing an N^2 update by replaying ALL the\n                // mutations on each document (instead of just the ones added) in\n                // this batch.\n                var keys = batch.keys();\n                return _this.localDocuments.getDocuments(txn, keys);\n            })\n                .next(function (changedDocuments) {\n                return { batchId: batch.batchId, changes: changedDocuments };\n            });\n        });\n    };\n    /**\n     * Acknowledge the given batch.\n     *\n     * On the happy path when a batch is acknowledged, the local store will\n     *\n     *  + remove the batch from the mutation queue;\n     *  + apply the changes to the remote document cache;\n     *  + recalculate the latency compensated view implied by those changes (there\n     *    may be mutations in the queue that affect the documents but haven't been\n     *    acknowledged yet); and\n     *  + give the changed documents back the sync engine\n     *\n     * @returns The resulting (modified) documents.\n     */\n    LocalStore.prototype.acknowledgeBatch = function (batchResult) {\n        var _this = this;\n        return this.persistence.runTransaction('Acknowledge batch', function (txn) {\n            var affected;\n            return _this.mutationQueue\n                .acknowledgeBatch(txn, batchResult.batch, batchResult.streamToken)\n                .next(function () {\n                if (_this.shouldHoldBatchResult(batchResult.commitVersion)) {\n                    _this.heldBatchResults.push(batchResult);\n                    affected = documentKeySet();\n                    return PersistencePromise.resolve();\n                }\n                else {\n                    var documentBuffer_1 = new RemoteDocumentChangeBuffer(_this.remoteDocuments);\n                    return _this.releaseBatchResults(txn, [batchResult], documentBuffer_1).next(function (promisedAffectedKeys) {\n                        affected = promisedAffectedKeys;\n                        return documentBuffer_1.apply(txn);\n                    });\n                }\n            })\n                .next(function () {\n                return _this.mutationQueue.performConsistencyCheck(txn);\n            })\n                .next(function () {\n                return _this.localDocuments.getDocuments(txn, affected);\n            });\n        });\n    };\n    /**\n     * Remove mutations from the MutationQueue for the specified batch;\n     * LocalDocuments will be recalculated.\n     *\n     * @returns The resulting modified documents.\n     */\n    LocalStore.prototype.rejectBatch = function (batchId) {\n        var _this = this;\n        return this.persistence.runTransaction('Reject batch', function (txn) {\n            var toReject;\n            var affectedKeys;\n            return _this.mutationQueue\n                .lookupMutationBatch(txn, batchId)\n                .next(function (promisedToReject) {\n                assert(promisedToReject != null, 'Attempt to reject nonexistent batch!');\n                toReject = promisedToReject;\n                return _this.mutationQueue\n                    .getHighestAcknowledgedBatchId(txn)\n                    .next(function (lastAcked) {\n                    assert(batchId > lastAcked, \"Acknowledged batches can't be rejected.\");\n                    return toReject;\n                });\n            })\n                .next(function () {\n                return _this.removeMutationBatch(txn, toReject);\n            })\n                .next(function (promisedAffectedKeys) {\n                affectedKeys = promisedAffectedKeys;\n                return _this.mutationQueue.performConsistencyCheck(txn);\n            })\n                .next(function () {\n                return _this.localDocuments.getDocuments(txn, affectedKeys);\n            });\n        });\n    };\n    /** Returns the last recorded stream token for the current user. */\n    LocalStore.prototype.getLastStreamToken = function () {\n        var _this = this;\n        return this.persistence.runTransaction('Get last stream token', function (txn) {\n            return _this.mutationQueue.getLastStreamToken(txn);\n        });\n    };\n    /**\n     * Sets the stream token for the current user without acknowledging any\n     * mutation batch. This is usually only useful after a stream handshake or in\n     * response to an error that requires clearing the stream token.\n     */\n    LocalStore.prototype.setLastStreamToken = function (streamToken) {\n        var _this = this;\n        return this.persistence.runTransaction('Set last stream token', function (txn) {\n            return _this.mutationQueue.setLastStreamToken(txn, streamToken);\n        });\n    };\n    /**\n     * Returns the last consistent snapshot processed (used by the RemoteStore to\n     * determine whether to buffer incoming snapshots from the backend).\n     */\n    LocalStore.prototype.getLastRemoteSnapshotVersion = function () {\n        return this.queryCache.getLastRemoteSnapshotVersion();\n    };\n    /**\n     * Update the \"ground-state\" (remote) documents. We assume that the remote\n     * event reflects any write batches that have been acknowledged or rejected\n     * (i.e. we do not re-apply local mutations to updates from this event).\n     *\n     * LocalDocuments are re-calculated if there are remaining mutations in the\n     * queue.\n     */\n    LocalStore.prototype.applyRemoteEvent = function (remoteEvent) {\n        var _this = this;\n        var documentBuffer = new RemoteDocumentChangeBuffer(this.remoteDocuments);\n        return this.persistence.runTransaction('Apply remote event', function (txn) {\n            var promises = [];\n            objUtils.forEachNumber(remoteEvent.targetChanges, function (targetId, change) {\n                // Do not ref/unref unassigned targetIds - it may lead to leaks.\n                var queryData = _this.targetIds[targetId];\n                if (!queryData)\n                    return;\n                var mapping = change.mapping;\n                if (mapping) {\n                    // First make sure that all references are deleted\n                    if (mapping instanceof ResetMapping) {\n                        promises.push(_this.queryCache\n                            .removeMatchingKeysForTargetId(txn, targetId)\n                            .next(function () {\n                            return _this.queryCache.addMatchingKeys(txn, mapping.documents, targetId);\n                        }));\n                    }\n                    else if (mapping instanceof UpdateMapping) {\n                        promises.push(_this.queryCache\n                            .removeMatchingKeys(txn, mapping.removedDocuments, targetId)\n                            .next(function () {\n                            return _this.queryCache.addMatchingKeys(txn, mapping.addedDocuments, targetId);\n                        }));\n                    }\n                    else {\n                        return fail('Unknown mapping type: ' + JSON.stringify(mapping));\n                    }\n                }\n                // Update the resume token if the change includes one. Don't clear\n                // any preexisting value.\n                var resumeToken = change.resumeToken;\n                if (resumeToken.length > 0) {\n                    queryData = queryData.update({\n                        resumeToken: resumeToken,\n                        snapshotVersion: change.snapshotVersion\n                    });\n                    _this.targetIds[targetId] = queryData;\n                    promises.push(_this.queryCache.addQueryData(txn, queryData));\n                }\n            });\n            var changedDocKeys = documentKeySet();\n            remoteEvent.documentUpdates.forEach(function (key, doc) {\n                changedDocKeys = changedDocKeys.add(key);\n                promises.push(documentBuffer.getEntry(txn, key).next(function (existingDoc) {\n                    // Make sure we don't apply an old document version to the remote\n                    // cache, though we make an exception for SnapshotVersion.MIN which\n                    // can happen for manufactured events (e.g. in the case of a limbo\n                    // document resolution failing).\n                    if (existingDoc == null ||\n                        doc.version.equals(SnapshotVersion.MIN) ||\n                        doc.version.compareTo(existingDoc.version) >= 0) {\n                        documentBuffer.addEntry(doc);\n                    }\n                    else {\n                        log.debug(LOG_TAG, 'Ignoring outdated watch update for ', key, '. Current version:', existingDoc.version, ' Watch version:', doc.version);\n                    }\n                    // The document might be garbage because it was unreferenced by\n                    // everything. Make sure to mark it as garbage if it is...\n                    _this.garbageCollector.addPotentialGarbageKey(key);\n                }));\n            });\n            // HACK: The only reason we allow a null snapshot version is so that we\n            // can synthesize remote events when we get permission denied errors while\n            // trying to resolve the state of a locally cached document that is in\n            // limbo.\n            var lastRemoteVersion = _this.queryCache.getLastRemoteSnapshotVersion();\n            var remoteVersion = remoteEvent.snapshotVersion;\n            if (!remoteVersion.equals(SnapshotVersion.MIN)) {\n                assert(remoteVersion.compareTo(lastRemoteVersion) >= 0, 'Watch stream reverted to previous snapshot?? ' +\n                    remoteVersion +\n                    ' < ' +\n                    lastRemoteVersion);\n                promises.push(_this.queryCache.setLastRemoteSnapshotVersion(txn, remoteVersion));\n            }\n            var releasedWriteKeys;\n            return PersistencePromise.waitFor(promises)\n                .next(function () { return _this.releaseHeldBatchResults(txn, documentBuffer); })\n                .next(function (promisedReleasedWriteKeys) {\n                releasedWriteKeys = promisedReleasedWriteKeys;\n                return documentBuffer.apply(txn);\n            })\n                .next(function () {\n                return _this.localDocuments.getDocuments(txn, changedDocKeys.unionWith(releasedWriteKeys));\n            });\n        });\n    };\n    /**\n     * Notify local store of the changed views to locally pin documents.\n     */\n    LocalStore.prototype.notifyLocalViewChanges = function (viewChanges) {\n        var _this = this;\n        return this.persistence.runTransaction('Notify local view changes', function (txn) {\n            var promises = [];\n            var _loop_1 = function (view) {\n                promises.push(_this.queryCache\n                    .getQueryData(txn, view.query)\n                    .next(function (queryData) {\n                    assert(queryData !== null, 'Local view changes contain unallocated query.');\n                    var targetId = queryData.targetId;\n                    _this.localViewReferences.addReferences(view.addedKeys, targetId);\n                    _this.localViewReferences.removeReferences(view.removedKeys, targetId);\n                }));\n            };\n            for (var _i = 0, viewChanges_1 = viewChanges; _i < viewChanges_1.length; _i++) {\n                var view = viewChanges_1[_i];\n                _loop_1(view);\n            }\n            return PersistencePromise.waitFor(promises);\n        });\n    };\n    /**\n     * Gets the mutation batch after the passed in batchId in the mutation queue\n     *  or null if empty.\n     *  @param afterBatchId If provided, the batch to search after.\n     *  @returns The next mutation or null if there wasn't one.\n     */\n    LocalStore.prototype.nextMutationBatch = function (afterBatchId) {\n        var _this = this;\n        return this.persistence.runTransaction('Get next mutation batch', function (txn) {\n            if (afterBatchId === undefined) {\n                afterBatchId = BATCHID_UNKNOWN;\n            }\n            return _this.mutationQueue.getNextMutationBatchAfterBatchId(txn, afterBatchId);\n        });\n    };\n    /**\n     * Read the current value of a Document with a given key or null if not\n     * found - used for testing.\n     */\n    LocalStore.prototype.readDocument = function (key) {\n        var _this = this;\n        return this.persistence.runTransaction('read document', function (txn) {\n            return _this.localDocuments.getDocument(txn, key);\n        });\n    };\n    /**\n     * Assigns the given query an internal ID so that its results can be pinned so\n     * they don't get GC'd. A query must be allocated in the local store before\n     * the store can be used to manage its view.\n     */\n    LocalStore.prototype.allocateQuery = function (query) {\n        var _this = this;\n        return this.persistence.runTransaction('Allocate query', function (txn) {\n            var queryData;\n            return _this.queryCache\n                .getQueryData(txn, query)\n                .next(function (cached) {\n                if (cached) {\n                    // This query has been listened to previously, so reuse the\n                    // previous targetID.\n                    // TODO(mcg): freshen last accessed date?\n                    queryData = cached;\n                    return PersistencePromise.resolve();\n                }\n                else {\n                    var targetId = _this.targetIdGenerator.next();\n                    queryData = new QueryData(query, targetId, QueryPurpose.Listen);\n                    return _this.queryCache.addQueryData(txn, queryData);\n                }\n            })\n                .next(function () {\n                assert(!_this.targetIds[queryData.targetId], 'Tried to allocate an already allocated query: ' + query);\n                _this.targetIds[queryData.targetId] = queryData;\n                return queryData;\n            });\n        });\n    };\n    /** Unpin all the documents associated with the given query. */\n    LocalStore.prototype.releaseQuery = function (query) {\n        var _this = this;\n        return this.persistence.runTransaction('Release query', function (txn) {\n            return _this.queryCache\n                .getQueryData(txn, query)\n                .next(function (queryData) {\n                assert(queryData != null, 'Tried to release nonexistent query: ' + query);\n                _this.localViewReferences.removeReferencesForId(queryData.targetId);\n                delete _this.targetIds[queryData.targetId];\n                if (_this.garbageCollector.isEager) {\n                    return _this.queryCache.removeQueryData(txn, queryData);\n                }\n                else {\n                    return PersistencePromise.resolve();\n                }\n            })\n                .next(function () {\n                // If this was the last watch target, then we won't get any more\n                // watch snapshots, so we should release any held batch results.\n                if (objUtils.isEmpty(_this.targetIds)) {\n                    var documentBuffer_2 = new RemoteDocumentChangeBuffer(_this.remoteDocuments);\n                    return _this.releaseHeldBatchResults(txn, documentBuffer_2).next(function () {\n                        documentBuffer_2.apply(txn);\n                    });\n                }\n                else {\n                    return PersistencePromise.resolve();\n                }\n            });\n        });\n    };\n    /**\n     * Runs the specified query against all the documents in the local store and\n     * returns the results.\n     */\n    LocalStore.prototype.executeQuery = function (query) {\n        var _this = this;\n        return this.persistence.runTransaction('Execute query', function (txn) {\n            return _this.localDocuments.getDocumentsMatchingQuery(txn, query);\n        });\n    };\n    /**\n     * Returns the keys of the documents that are associated with the given\n     * target id in the remote table.\n     */\n    LocalStore.prototype.remoteDocumentKeys = function (targetId) {\n        var _this = this;\n        return this.persistence.runTransaction('Remote document keys', function (txn) {\n            return _this.queryCache.getMatchingKeysForTargetId(txn, targetId);\n        });\n    };\n    /**\n     * Collect garbage if necessary.\n     * Should be called periodically by Sync Engine to recover resources. The\n     * implementation must guarantee that GC won't happen in other places than\n     * this method call.\n     */\n    LocalStore.prototype.collectGarbage = function () {\n        var _this = this;\n        // Call collectGarbage regardless of whether isGCEnabled so the referenceSet\n        // doesn't continue to accumulate the garbage keys.\n        return this.persistence.runTransaction('Garbage collection', function (txn) {\n            return _this.garbageCollector.collectGarbage(txn).next(function (garbage) {\n                var promises = [];\n                garbage.forEach(function (key) {\n                    promises.push(_this.remoteDocuments.removeEntry(txn, key));\n                });\n                return PersistencePromise.waitFor(promises);\n            });\n        });\n    };\n    LocalStore.prototype.releaseHeldBatchResults = function (txn, documentBuffer) {\n        var toRelease = [];\n        for (var _i = 0, _a = this.heldBatchResults; _i < _a.length; _i++) {\n            var batchResult = _a[_i];\n            if (!this.isRemoteUpToVersion(batchResult.commitVersion)) {\n                break;\n            }\n            toRelease.push(batchResult);\n        }\n        if (toRelease.length === 0) {\n            return PersistencePromise.resolve(documentKeySet());\n        }\n        else {\n            this.heldBatchResults.splice(0, toRelease.length);\n            return this.releaseBatchResults(txn, toRelease, documentBuffer);\n        }\n    };\n    LocalStore.prototype.isRemoteUpToVersion = function (version) {\n        // If there are no watch targets, then we won't get remote snapshots, and\n        // we are always \"up-to-date.\"\n        var lastRemoteVersion = this.queryCache.getLastRemoteSnapshotVersion();\n        return (version.compareTo(lastRemoteVersion) <= 0 ||\n            objUtils.isEmpty(this.targetIds));\n    };\n    LocalStore.prototype.shouldHoldBatchResult = function (version) {\n        // Check if watcher isn't up to date or prior results are already held.\n        return (!this.isRemoteUpToVersion(version) || this.heldBatchResults.length > 0);\n    };\n    LocalStore.prototype.releaseBatchResults = function (txn, batchResults, documentBuffer) {\n        var _this = this;\n        var promiseChain = PersistencePromise.resolve();\n        var _loop_2 = function (batchResult) {\n            promiseChain = promiseChain.next(function () {\n                return _this.applyWriteToRemoteDocuments(txn, batchResult, documentBuffer);\n            });\n        };\n        for (var _i = 0, batchResults_1 = batchResults; _i < batchResults_1.length; _i++) {\n            var batchResult = batchResults_1[_i];\n            _loop_2(batchResult);\n        }\n        return promiseChain.next(function () {\n            return _this.removeMutationBatches(txn, batchResults.map(function (result) { return result.batch; }));\n        });\n    };\n    LocalStore.prototype.removeMutationBatch = function (txn, batch) {\n        return this.removeMutationBatches(txn, [batch]);\n    };\n    /** Removes all the mutation batches named in the given array. */\n    LocalStore.prototype.removeMutationBatches = function (txn, batches) {\n        var affectedDocs = documentKeySet();\n        for (var _i = 0, batches_2 = batches; _i < batches_2.length; _i++) {\n            var batch = batches_2[_i];\n            for (var _a = 0, _b = batch.mutations; _a < _b.length; _a++) {\n                var mutation = _b[_a];\n                var key = mutation.key;\n                affectedDocs = affectedDocs.add(key);\n            }\n        }\n        return this.mutationQueue\n            .removeMutationBatches(txn, batches)\n            .next(function () { return affectedDocs; });\n    };\n    LocalStore.prototype.applyWriteToRemoteDocuments = function (txn, batchResult, documentBuffer) {\n        var batch = batchResult.batch;\n        var docKeys = batch.keys();\n        var promiseChain = PersistencePromise.resolve();\n        docKeys.forEach(function (docKey) {\n            promiseChain = promiseChain\n                .next(function () {\n                return documentBuffer.getEntry(txn, docKey);\n            })\n                .next(function (remoteDoc) {\n                var doc = remoteDoc;\n                var ackVersion = batchResult.docVersions.get(docKey);\n                assert(ackVersion !== null, 'ackVersions should contain every doc in the write.');\n                if (!doc || doc.version.compareTo(ackVersion) < 0) {\n                    doc = batch.applyToRemoteDocument(docKey, doc, batchResult);\n                    if (!doc) {\n                        assert(!remoteDoc, 'Mutation batch ' +\n                            batch +\n                            ' applied to document ' +\n                            remoteDoc +\n                            ' resulted in null');\n                    }\n                    else {\n                        documentBuffer.addEntry(doc);\n                    }\n                }\n            });\n        });\n        return promiseChain;\n    };\n    return LocalStore;\n}());\nexport { LocalStore };\n\n\n"]}